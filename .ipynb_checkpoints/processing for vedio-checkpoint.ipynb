{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### this file just is used to process vedio using class Line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "from collections import deque\n",
    "\n",
    "def find_corners(img,nx=9,ny=6,show=True):\n",
    "    '''\n",
    "    this function just for find corners in img. return corners\n",
    "    '''\n",
    "    ##read imgae\n",
    "    image = cv2.imread(img)\n",
    "    original = image # save original image\n",
    "    ##convert to gray\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chessboard corner\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "     # If found, draw corners\n",
    "    if ret == True and show == True:\n",
    "       # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(image, (nx, ny), corners, ret)\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(8,4))\n",
    "        ax1.set_title('Original Image', fontsize=18)\n",
    "        ax1.imshow(cv2.cvtColor(cv2.imread(img),cv2.COLOR_BGR2RGB))#must be cv2.imread(img),if it is the original , the result is tha same as image\n",
    "        ax2.set_title(\"After finding corners\",fontsize=18)\n",
    "        ax2.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))\n",
    "    return ret,corners\n",
    "##find all corners in image\n",
    "nx = 9\n",
    "ny = 6\n",
    "objp = np.zeros((nx*ny,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2) #like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "\n",
    "objpoints = [] #3D point in real world\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "for image in images:\n",
    "    ret,corners = find_corners(image)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line():\n",
    "    def __init__(self):\n",
    "         # Was the line found in the previous frame?\n",
    "        self.found = False\n",
    "        \n",
    "        # Remember x and y values of lanes in previous frame\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        \n",
    "        # Store recent x intercepts for averaging across frames\n",
    "        self.xbottom = deque(maxlen=10)\n",
    "        self.xtop = deque(maxlen=10)\n",
    "        \n",
    "        # Remember previous x intercept to compare against current one\n",
    "        self.lastx_bottom = None\n",
    "        self.lastx_top = None\n",
    "        \n",
    "        # Remember radius of curvature\n",
    "        self.radius = None\n",
    "        \n",
    "        # Store recent polynomial coefficients for averaging across frames\n",
    "        self.fit0 = deque(maxlen=10)\n",
    "        self.fit1 = deque(maxlen=10)\n",
    "        self.fit2 = deque(maxlen=10)\n",
    "        self.fitx = None\n",
    "        self.pts = []\n",
    "        \n",
    "        # Count the number of frames\n",
    "        self.count = 0\n",
    "    \n",
    "    def blind_search(self,x,y,image):\n",
    "        '''\n",
    "        this function is used in first few frames or when  the line can not be find in previous frame\n",
    "        It uses a slinding window approach to detect peaks in a histogram of the\n",
    "        binary thresholded image. Pixels in close proimity to the detected peaks are considered to belong\n",
    "        to the lane lines.\n",
    "        input argument:\n",
    "        x, y = np.nonzero(np.transpose(combined_binary)),return the index\n",
    "        '''\n",
    "        #find point in the line\n",
    "        xvals = []\n",
    "        yvals = []\n",
    "        nwindows = 9\n",
    "        windows_height = np.int(image.shape[0]//nwindows)\n",
    "        # Set the width of the windows +/- margin in  x direction\n",
    "        margin = 100\n",
    "        # Set minimum number of pixels found to recenter window\n",
    "        minpix = 50\n",
    "        if self.found == False:\n",
    "            for i in range(nwindows):\n",
    "                top = 720-i*windows_height\n",
    "                bottom = 720-(i+1)*windows_height\n",
    "                histogram = np.sum(image[bottom:top,:],axis=0)\n",
    "                midpoint = np.int(histogram.shape[0]//2)\n",
    "                if self == Left:\n",
    "                    peak = np.argmax(histogram[:midpoint])\n",
    "                if self == Right:\n",
    "                    peak = np.argmax(histogram[midpoint+1:])+midpoint\n",
    "                low = peak - margin\n",
    "                high = peak + margin#should be noticed that may be over the indice\n",
    "                x_idx = np.where(((low < x)&(x < high)&((y > bottom) & (y < top))))\n",
    "                x_window, y_window = x[x_idx], y[x_idx]\n",
    "                if np.sum(x_window) != 0:\n",
    "                    xvals.extend(x_window)\n",
    "                    yvals.extend(y_window)\n",
    "            if np.sum(xvals) > 0:\n",
    "                self.found = True\n",
    "            else:\n",
    "                xvals = self.X\n",
    "                yvals = self.Y\n",
    "                \n",
    "        return xvals,yvals,self.found\n",
    "    \n",
    "    def follow_search(self,x,y,image):\n",
    "        '''\n",
    "        This function is applied when the lane lines have been detected in the previous frame.\n",
    "        It uses a sliding window to search for lane pixels in close proximity (+/- 25 pixels in the x direction)\n",
    "        around the previous detected polynomial.\n",
    "        '''\n",
    "        xvals = []\n",
    "        yvals = []\n",
    "        nwindows = 9\n",
    "        windows_height = np.int(image.shape[0]//nwindows)\n",
    "        if self.found == False:\n",
    "            for i in range(nwindows):\n",
    "                top = 720-i*windows_height\n",
    "                bottom = 720-(i+1)*windows_height\n",
    "                yval = np.mean([bottom,top])\n",
    "                #use the fit parameter of previous 10 frames to calculate\n",
    "                #equal to the peak\n",
    "                xval = np.mean(self.fit0)*yval**2 + np.mean(self.fit1)*yval + np.mean(self.fit2)\n",
    "                idx = np.where((x > (xval-margin))& (x < (xval+margin)) & (y < top)&(y > bottom))\n",
    "                x_windows,y_windows = x[idx],y[idx]\n",
    "                if np.sum(x_windows) != 0:\n",
    "                    xvals.extend(x_windows)\n",
    "                    yvals.extend(y_windows)\n",
    "            if np.sum(xvals) != 0:\n",
    "                self.found = True\n",
    "            else:\n",
    "                xvals = self.X\n",
    "                yvals = self.Y\n",
    "        return xvals,yvals,self.found\n",
    "                \n",
    "    def radius_of_curvature(self, xvals, yvals):\n",
    "        ym_per_pix = 30./720 # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/700 # meteres per pixel in x dimension\n",
    "        #fit = np.polyfit(xvals*xm_per_pix,yvals*ym_per_pix,2)\n",
    "        fit_cr = np.polyfit(yvals*ym_per_pix,xvals*xm_per_pix,2)\n",
    "        #calculate the radius,曲率\n",
    "        curverad = ((1 + (2*fit_cr[0]*np.max(yvals) + fit_cr[1])**2)**1.5) \\\n",
    "                                     /np.absolute(2*fit_cr[0])\n",
    "        return curverad\n",
    "    \n",
    "    \n",
    "    def sort_vals(self, xvals, yvals):\n",
    "        sorted_index = np.argsort(yvals)#return the sorted result index\n",
    "        sorted_yvals = yvals[sorted_index]\n",
    "        sorted_xvals = xvals[sorted_index]\n",
    "        return sorted_xvals, sorted_yvals\n",
    "    \n",
    "    \n",
    "    def get_intercepts(self, polynomial):\n",
    "        '''\n",
    "        get the intercept of this polynomial,when x= 0\n",
    "        '''\n",
    "        bottom = polynomial[0]*720**2 + polynomial[1]*720 + polynomial[2]\n",
    "        top = polynomial[0]*0**2 + polynomial[1]*0 + polynomial[2]\n",
    "        return bottom, top\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_vid(image,show=True):\n",
    "    global Right,Left\n",
    "    img_size = (image.shape[1], image.shape[0])\n",
    "     # Calibrate camera and undistort image\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "    undist = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    #perspective transform\n",
    "    offset = 0\n",
    "    src = np.float32([[490, 482],[810, 482],\n",
    "                      [1250, 720],[40, 720]])\n",
    "    dst = np.float32([[offset,offset],[img_size[0]-offset, offset],\n",
    "                                      [img_size[0]-offset,img_size[1]-offset],\n",
    "                                     [offset,img_size[1]-offset]])\n",
    "    #birds eye\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(undist, M, img_size)\n",
    "    \n",
    "    #color and gradient combined,but i learn it from other's project that may be different color channel is better than gradient\n",
    "    #change to hls\n",
    "    hls = cv2.cvtColor(warped,cv2.COLOR_BGR2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    l_channel = cv2.cvtColor(warped, cv2.COLOR_BGR2LUV)[:,:,0]\n",
    "    b_channel = cv2.cvtColor(warped, cv2.COLOR_BGR2Lab)[:,:,2]\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_thresh_min = 180\n",
    "    s_thresh_max = 255\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh_min) & (s_channel <= s_thresh_max)] = 1\n",
    "    \n",
    "    l_thresh_min = 150\n",
    "    l_thresh_max = 255\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= l_thresh_min) & (l_channel <= l_thresh_max)] = 1\n",
    "    \n",
    "    b_thresh_min = 150\n",
    "    b_thresh_max = 255\n",
    "    b_binary = np.zeros_like(b_channel)\n",
    "    b_binary[(b_channel >= b_thresh_min)&(b_channel <= b_thresh_max)] = 1\n",
    "    \n",
    "    combined_binary = np.zeros_like(b_binary)\n",
    "    combined_binary[(l_binary == 1) | (b_binary == 1)] = 1\n",
    "    \n",
    "    # Identify all non zero pixels in the image\n",
    "    x, y = np.nonzero(np.transpose(combined_binary)) #return two arrays ,one for rows, another for cols\n",
    "    \n",
    "    #start to process image using class line\n",
    "    # put the true in the first. if put it second ,it will run again\n",
    "    if Left.found == True:\n",
    "        left_x,left_y,Left.found = Left.follow_search(x,y,combined_binary)\n",
    "    \n",
    "    if Right.found == True:\n",
    "        right_x,right_y,Right.found = Right.follow_search(x,y,combined_binary)\n",
    "        \n",
    "    if Right.found == False:\n",
    "        right_x,right_y,Right.found = Right.blind_search(x,y,combined_binary)\n",
    "        \n",
    "    if Left.found == False:\n",
    "        left_x,left_y, Left.found = Left.blind_search(x,y,combined_binary)\n",
    "    \n",
    "    \n",
    "    #make sure the result has the same type\n",
    "    lefty = np.array(lefty).astype(np.float32)\n",
    "    leftx = np.array(leftx).astype(np.float32)\n",
    "    righty = np.array(righty).astype(np.float32)\n",
    "    rightx = np.array(rightx).astype(np.float32)\n",
    "    \n",
    "            \n",
    "    # Calculate left polynomial fit based on detected pixels\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    \n",
    "    # Calculate intercepts to extend the polynomial to the top and bottom of warped image\n",
    "    leftx_bottom, leftx_top = Left.get_intercepts(left_fit)\n",
    "    \n",
    "    # Average intercepts across n frames\n",
    "    Left.xbottom.append(leftx_bottom)\n",
    "    Left.xtop.append(leftx_top)\n",
    "    leftx_bottom = np.mean(Left.xbottom)\n",
    "    leftx_top = np.mean(Left.xtop)\n",
    "    Left.lastx_bottom = leftx_bottom\n",
    "    Left.lastx_top = leftx_top\n",
    "    \n",
    "    # Add averaged intercepts to current x and y vals\n",
    "    leftx = np.append(leftx, leftx_bottom)\n",
    "    lefty = np.append(lefty, 720)\n",
    "    leftx = np.append(leftx, leftx_top)\n",
    "    lefty = np.append(lefty, 0)\n",
    "    \n",
    "    # Sort detected pixels based on the yvals\n",
    "    leftx, lefty = Left.sort_vals(leftx, lefty)\n",
    "    \n",
    "    Left.X = leftx\n",
    "    Left.Y = lefty\n",
    "    \n",
    "    # Recalculate polynomial with intercepts and average across n frames\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    Left.fit0.append(left_fit[0])\n",
    "    Left.fit1.append(left_fit[1])\n",
    "    Left.fit2.append(left_fit[2])\n",
    "    left_fit = [np.mean(Left.fit0), \n",
    "                np.mean(Left.fit1), \n",
    "                np.mean(Left.fit2)]\n",
    "    \n",
    "    # Fit polynomial to detected pixels\n",
    "    left_fitx = left_fit[0]*lefty**2 + left_fit[1]*lefty + left_fit[2]\n",
    "    Left.fitx = left_fitx\n",
    "    \n",
    "    # Calculate right polynomial fit based on detected pixels\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Calculate intercepts to extend the polynomial to the top and bottom of warped image\n",
    "    rightx_bottom, rightx_top = Right.get_intercepts(right_fit)\n",
    "    \n",
    "    # Average intercepts across 5 frames\n",
    "    Right.xbottom.append(rightx_bottom)\n",
    "    Right.xtop.append(rightx_top)\n",
    "    rightx_bottom = np.mean(Right.xbottom)\n",
    "    rightx_top = np.mean(Right.xtop)\n",
    "    Right.lastx_bottom = rightx_bottom\n",
    "    Right.lastx_top = rightx_top\n",
    "    rightx = np.append(rightx, rightx_bottom)\n",
    "    righty = np.append(righty, 720)\n",
    "    rightx = np.append(rightx, rightx_top)\n",
    "    righty = np.append(righty, 0)\n",
    "    \n",
    "    # Sort right lane pixels\n",
    "    rightx, righty = Right.sort_vals(rightx, righty)\n",
    "    Right.X = rightx\n",
    "    Right.Y = righty\n",
    "    \n",
    "    # Recalculate polynomial with intercepts and average across n frames\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    Right.fit0.append(right_fit[0])\n",
    "    Right.fit1.append(right_fit[1])\n",
    "    Right.fit2.append(right_fit[2])\n",
    "    right_fit = [np.mean(Right.fit0), np.mean(Right.fit1), np.mean(Right.fit2)]\n",
    "    \n",
    "    # Fit polynomial to detected pixels,the 10 frames mean value\n",
    "    right_fitx = right_fit[0]*righty**2 + right_fit[1]*righty + right_fit[2]\n",
    "    Right.fitx = right_fitx\n",
    "    \n",
    "    # Compute radius of curvature for each lane in meters\n",
    "    left_curverad = Left.radius_of_curvature(leftx, lefty)\n",
    "    right_curverad = Right.radius_of_curvature(rightx, righty)\n",
    "    \n",
    "    # Only print the radius of curvature every 3 frames for improved readability\n",
    "    if Left.count % 3 == 0:\n",
    "        Left.radius = left_curverad\n",
    "        Right.radius = right_curverad\n",
    "        \n",
    "    # Calculate the vehicle position relative to the center of the lane\n",
    "    position = (rightx_bottom+leftx_bottom)/2\n",
    "    distance_from_center = abs((640 - position)*3.7/700) \n",
    "    \n",
    "    ## change to real image\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    # draw the result    \n",
    "    warp_zero = np.zeros_like(combined_binary).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero)) ##birds eye\n",
    "    pts_left = np.array([np.flipud(np.transpose(np.vstack([Left.fitx, Left.Y])))])\n",
    "    pts_right = np.array([np.transpose(np.vstack([Right.fitx, Right.Y]))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    cv2.polylines(color_warp, np.int_([pts]), isClosed=False, color=(0,0,255), thickness = 40)\n",
    "    cv2.fillPoly(color_warp, np.int_(pts), (34,255,34))\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0]))##change to real world\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.5, 0)\n",
    "    \n",
    "    Left.count += 1\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-772b4b3d1900>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mvideo_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'result.mp4'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mclip1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"project_video.mp4\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mwhite_clip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_vid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mwhite_clip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_videofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lily0101\\Anaconda3\\lib\\site-packages\\moviepy\\video\\VideoClip.py\u001b[0m in \u001b[0;36mfl_image\u001b[1;34m(self, image_func, apply_to)\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0manother\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mimage_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m         \"\"\"\n\u001b[1;32m--> 533\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;31m# --------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lily0101\\Anaconda3\\lib\\site-packages\\moviepy\\Clip.py\u001b[0m in \u001b[0;36mfl\u001b[1;34m(self, fun, apply_to, keep_duration)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;31m#mf = copy(self.make_frame)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[0mnewclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-179>\u001b[0m in \u001b[0;36mset_make_frame\u001b[1;34m(self, mf)\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lily0101\\Anaconda3\\lib\\site-packages\\moviepy\\decorators.py\u001b[0m in \u001b[0;36moutplace\u001b[1;34m(f, clip, *a, **k)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;34m\"\"\" Applies f(clip.copy(), *a, **k) and returns clip.copy()\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mnewclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewclip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnewclip\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lily0101\\Anaconda3\\lib\\site-packages\\moviepy\\video\\VideoClip.py\u001b[0m in \u001b[0;36mset_make_frame\u001b[1;34m(self, mf)\u001b[0m\n\u001b[0;32m    692\u001b[0m         \"\"\"\n\u001b[0;32m    693\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-136>\u001b[0m in \u001b[0;36mget_frame\u001b[1;34m(self, t)\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lily0101\\Anaconda3\\lib\\site-packages\\moviepy\\decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(f, *a, **kw)\u001b[0m\n\u001b[0;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[0;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lily0101\\Anaconda3\\lib\\site-packages\\moviepy\\Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[1;34m(self, t)\u001b[0m\n\u001b[0;32m     93\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lily0101\\Anaconda3\\lib\\site-packages\\moviepy\\Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;31m#mf = copy(self.make_frame)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[0mnewclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lily0101\\Anaconda3\\lib\\site-packages\\moviepy\\video\\VideoClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(gf, t)\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0manother\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mimage_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m         \"\"\"\n\u001b[1;32m--> 533\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;31m# --------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-2c0397e7b17c>\u001b[0m in \u001b[0;36mprocess_vid\u001b[1;34m(image, show)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mRight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfound\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mright_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mright_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mRight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblind_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcombined_binary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mLeft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfound\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "\n",
    "### Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "Left = Line()\n",
    "Right = Line()\n",
    "video_output = 'result.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\").subclip(0,2)\n",
    "white_clip = clip1.fl_image(process_vid) \n",
    "white_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<vedio wight = \"640\" height = \"320\" controls>\n",
    "<source src = \"{0}\">\n",
    "</vedio>\n",
    "\"\"\".format(\"result.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
